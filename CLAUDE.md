# CLAUDE.md

## Project Overview

**SentencifyAI** - React-based legal decision tool for Brazilian labor court judges.

**Version**: 1.32.41 | **File**: `SentencifyAI_v1_28.jsx` (~920 KB) | **Runtime**: Standalone + Vercel

## Architecture

**Hooks**: `useModalManager`, `useAIIntegration`, `useLocalStorage`, `useModelLibrary`, `useProofManager`, `useDocumentManager`, `useTopicManager`, `usePrimaryTabLock`, `useGlobalEditor`, `useChatAssistant`, `useFieldVersioning`

**Components**: `TopicCard`, `ModelCard`, `SuggestionCard`, `ProofCard`, `GlobalEditorModal`, `LockedTabOverlay`, `VersionSelect`

**Storage**:
- `SentencifyAI` (IndexedDB) ‚Üí modelos
- `sentencify-pdfs` (IndexedDB) ‚Üí PDFs
- `sentencify-versions` (IndexedDB) ‚Üí versionamento do campo fundamenta√ß√£o
- `sentencify-legislacao-embeddings` (IndexedDB) ‚Üí embeddings pr√©-computados da legisla√ß√£o
- `sentencify-juris-embeddings` (IndexedDB) ‚Üí embeddings pr√©-computados da jurisprud√™ncia
- `sentencifySession` (localStorage) ‚Üí metadados + textos
- Modelos NER/E5 (cache browser) ‚Üí baixados automaticamente do HuggingFace CDN

## Critical Guidelines

1. **Modals com Scroll**: Use `overflow-auto` no overlay + `my-auto` no container (ver DispositivoModal)
2. **File Rename (Windows)**: Use `powershell -Command "Rename-Item..."`
3. **API**: Use `buildApiRequest()` helper. Model: `claude-sonnet-4-20250514`
4. **z-index**: Base `z-50`, nested `+10` por n√≠vel

> **Nota**: Este projeto agora roda como aplica√ß√£o standalone (fora do sandbox Claude.ai). N√£o h√° mais limite de tamanho de arquivo nem necessidade de minifica√ß√£o.

## Recent Changes

| Version | Feature |
|---------|---------|
| v1.32.41 | Suporte a deploy Vercel: serverless functions (/api/*), API_BASE din√¢mico, vercel.json |
| v1.32.40 | Toggle para ativar/desativar logs de thinking no console (Config IA > logThinking) |
| v1.32.39 | Log de thinking no console do browser: Claude (extended thinking) e Gemini 3 (includeThoughts) para debug/an√°lise |
| v1.32.38 | Gemini thinking buffer: auto-aumenta maxOutputTokens baseado no thinking_level (high +16K, evita MAX_TOKENS) |
| v1.32.37 | Fix Gemini 3 Pro: validar thinking_level (Pro s√≥ suporta low/high, minimal/medium convertidos para low) |
| v1.32.36 | Removido Gemini 2.5: apenas Gemini 3 (Flash/Pro), UI simplificada (thinking_level apenas), migra√ß√£o autom√°tica de 2.5‚Üí3 |
| v1.32.35 | Fix Gemini thinking: extra√ß√£o de texto busca part sem thought=true (antes pegava parts[0] que era thinking block, retornando vazio) |
| v1.32.34 | Fix reorderTopicsViaLLM: regex mais robusto (suporta markdown code blocks, newlines no JSON) |
| v1.32.33 | Auto-timeout 5 min para thinking budgets >= 40K + warning "respostas podem demorar mais" |
| v1.32.32 | Budget thinking din√¢mico por modelo Claude: Sonnet at√© 62K, Opus at√© 30K + warning para budgets >= 40K |
| v1.32.31 | UI Gemini 2.5 Pro: toggle mostra "M√≠nimo" + badge "1024 tokens" quando thinking "desativado" (API n√£o permite desligar) |
| v1.32.30 | Fix thinking config: Gemini 2.5 Flash desativa com thinking_budget: 0 (antes undefined usava din√¢mico), 2.5 Pro usa m√≠nimo 1024 |
| v1.32.29 | Fix cr√≠tico Gemini: callGeminiAPI agora honra useInstructions - AI_INSTRUCTIONS enviadas como systemInstruction (13 funcionalidades corrigidas) |
| v1.32.28 | Chat assistente: verifica√ß√£o obrigat√≥ria - LLM deve listar informa√ß√µes pendentes ANTES de redigir qualquer texto de decis√£o |
| v1.32.27 | Chat assistente: instru√ß√£o de perguntas fortalecida - LLM deve perguntar quando informa√ß√£o n√£o estiver EXPRESSAMENTE no contexto, "prefira perguntar a presumir" |
| v1.32.26 | Chat assistente: maxTokens aumentado para 16000 (respostas longas) + log finishReason no servidor Gemini para diagn√≥stico |
| v1.32.25 | Fix reorderTopicsViaLLM: regex robusto para extrair JSON (ignora thinking tokens) + maxTokens 4000 (evita truncamento) |
| v1.32.24 | Modal de changelog: clique na vers√£o no header abre modal com hist√≥rico de altera√ß√µes (40 vers√µes) |
| v1.32.23 | T√≠tulos de t√≥picos com causa de pedir nuclear: prompt ajustado para gerar t√≠tulos como "RESCIS√ÉO INDIRETA - ASS√âDIO MORAL" quando relevante, melhorando busca sem√¢ntica |
| v1.32.22 | Sugest√µes de modelos usando apenas t√≠tulo: embedding da query usa s√≥ topic.title (categoria e relat√≥rio dilu√≠am relev√¢ncia) |
| v1.32.21 | Filtros antes do limit: filtros de tipo/tribunal aplicados ANTES de limitar em 30 resultados (aba e modal), permitindo at√© 30 do tipo selecionado |
| v1.32.20 | Fix case sensitivity E5: modelo √© sens√≠vel a mai√∫sculas/min√∫sculas, todas as queries convertidas para .toLowerCase() antes de gerar embedding (5 locais corrigidos) |
| v1.32.19 | Fix busca sem√¢ntica no modal de jurisprud√™ncia: exibi√ß√£o de texto corrigida (fallback para fullText/text), query usa apenas t√≠tulo do t√≥pico (n√£o relat√≥rio longo que dilu√≠a relev√¢ncia) |
| v1.32.18 | Busca sem√¢ntica de jurisprud√™ncia nos editores: toggle "ü§ñ Jurisprud√™ncia via IA Local" em Config IA, usa embeddings no JurisprudenciaModal (individual e global), texto do toggle de modelos atualizado para "Busca sem√¢ntica instant√¢nea" |
| v1.32.17 | NER sob demanda: modelo carrega s√≥ ao clicar "Detectar Nomes" e descarrega ap√≥s uso, economizando ~2GB RAM. dispose() libera mem√≥ria WASM corretamente |
| v1.32.16 | Bot√µes responsivos na aba T√≥picos: flex-nowrap + overflow-x-auto - bot√µes ficam na mesma linha com scroll horizontal quando necess√°rio |
| v1.32.15 | Tesseract alta qualidade: SCALE 4.0 (4x resolu√ß√£o) + PSM 6 (bloco √∫nico) + preserve_interword_spaces - melhor OCR para PDFs escaneados |
| v1.32.14 | Fix Tesseract em Provas: executeExtraction usava l√≥gica errada (for√ßava pdfjs), agora usa blockedModes igual aos Uploads |
| v1.32.13 | Permitir Tesseract com anonimiza√ß√£o: s√≥ bloquear claude-vision e pdf-puro (ambos enviam bin√°rio), PDF.js e Tesseract extraem texto ‚Üí podem anonimizar |
| v1.32.12 | Fix mergeOrgLoc: aceita ORG+ORG curto (modelo classifica cidades como ORG, n√£o LOC) - "COMPANHIA DE TRANSITO E TRANSPORTE DE MACAPA" agora funde corretamente |
| v1.32.11 | Bot√£o Manual do Usu√°rio (üìñ) no header - abre MANUAL_USUARIO_AVANCADO.html em nova aba |
| v1.32.10 | NER fus√£o ORG+LOC: mergeOrgLoc detecta padr√£o "ORG + DE/DO/DA + LOC" e funde em √∫nica ORG (ex: "COMPANHIA DE TRANSITO E TRANSPORTE DE MACAPA") |
| v1.32.09 | Fix NER modelo: trocado DistilBERT por BERT completo (Xenova/bert-base-multilingual-cased-ner-hrl) - mesmo modelo do sandbox, qualidade restaurada |
| v1.32.08 | IA Local via Web Worker: AIModelService roda em thread separada (UI nunca trava), SIMD+threads autom√°ticos via Transformers.js |
| v1.32.07 | Fix NER separa√ß√£o de nomes: restaurado l√≥gica v1.28 com offsets manuais via indexOf e distance para separar entidades n√£o-adjacentes |
| v1.32.06 | Auto-inicializa√ß√£o: modelos NER/E5 inicializam automaticamente ao carregar p√°gina se estavam ativados (sem precisar clicar "Baixar Agora") |
| v1.32.05 | Fix NER espa√ßamento: processTokens usa ## prefix para detectar subtokens (evita nomes concatenados) |
| v1.32.04 | Fix cache HTML: for√ßar env.allowRemoteModels=true e env.useBrowserCache=true para evitar cache de p√°ginas de erro |
| v1.32.03 | AIModelService sem Worker: execu√ß√£o na main thread com dynamic import (mais est√°vel com Vite) |
| v1.32.02 | Fix Worker: instala√ß√£o @xenova/transformers via npm, import direto no worker |
| v1.32.01 | Config IA: bot√£o "Baixar Agora" e barra de progresso para modelo E5-base, toggles NER e E5 com sub-toggles (legisla√ß√£o, jurisprud√™ncia, modelos, sugest√µes) |
| v1.32.00 | IA Local Refatora√ß√£o: Web Worker para n√£o bloquear UI, modelos do HuggingFace (Xenova/distilbert-multilingual-ner, Xenova/multilingual-e5-base), download autom√°tico, WASM otimizado (SIMD/threads), removido upload manual e LocalAIProcessingOverlay |
| v1.31.05 | Fix Anonimiza√ß√£o: permitir com Tesseract OCR (al√©m de PDF.js), removido App_min.jsx obsoleto |
| v1.31.04 | IA Local Otimiza√ß√£o: detectAICapabilities() para SIMD/threads/WebGPU, SIMD habilitado (97% browsers), proxy worker como fallback, multi-threading quando crossOriginIsolated |
| v1.31.03 | Tesseract OCR Batching: workers din√¢micos (75% cores, max 8), batching para limitar mem√≥ria em PDFs grandes |
| v1.31.02 | Tesseract OCR Paralelo: Scheduler com pool de workers (~3x mais r√°pido), renderiza√ß√£o e OCR em paralelo |
| v1.31.01 | Fix RECITATION Gemini: reorderTopicsViaLLM retorna √≠ndices ao inv√©s de t√≠tulos (evita corte por filtro de conte√∫do) |
| v1.31.00 | Tesseract.js OCR Offline: engine de OCR 100% offline para PDFs escaneados, gratuito, privacidade total, ~15-30s/p√°gina |
| v1.30.00 | Gemini Vision OCR: nova engine OCR para PDFs escaneados, 4x mais barato que Claude Vision (~$0.01/10 p√°ginas) |
| v1.29.05 | Desabilitar sugest√µes de modelos para t√≥picos especiais RELAT√ìRIO e DISPOSITIVO |
| v1.29.04 | Fix overlay NER: prop `message` customizada no LocalAIProcessingOverlay, texto correto "Detectando nomes..." |
| v1.29.03 | Overlay "IA Local Processando" no modal de anonimiza√ß√£o durante detec√ß√£o NER (uploads e provas) |
| v1.29.02 | Fix NER ORG: remover LTDA/EIRELI do STOP_WORDS_CONTAINS, fuzzy dedup separado por tipo (PER vs ORG), threshold ORG 85% |
| v1.29.01 | Fix NER ORG: remover LTDA/EIRELI/S.A do STOP_WORDS (s√£o sufixos v√°lidos), threshold reduzido para 85% |
| v1.29.00 | NER incluir ORG (empresas): toggle em Config IA, STOP_WORDS para tribunais/√≥rg√£os p√∫blicos, filtro score ‚â• 90%, persist√™ncia localStorage |
| v1.28.18 | Cleanup NER: removido regex de resgate - causava sobreposi√ß√£o e quebrava fus√£o de nomes |
| v1.28.17 | Cleanup NER: removido regex de completar preposi√ß√£o (v1.28.10) - offsets manuais resolvem fragmenta√ß√£o |
| v1.28.16 | Fix NER: offsets manuais via `indexOf` + filtro [CLS]/[SEP]/[UNK] - resolve fragmenta√ß√£o de nomes |
| v1.28.15 | Fix NER offsets manuais via `indexOf` + `aggregation_strategy: 'none'` (causou erro "offset out of bounds") |
| v1.28.14 | NER reconstru√ß√£o baseada em offsets (falhou: Transformers.js retorna start/end zerados) |
| v1.28.13 | Fix tokeniza√ß√£o fragmentada no NER LeNER-BR: `aggregation_strategy: 'average'` (n√£o funcionou no Transformers.js) |
| v1.28.12 | NER suporta modelo LeNER-BR jur√≠dico (tag PESSOA al√©m de PER) - F1 0.983 para pessoas |
| v1.28.11 | NER permite nomes curtos (4+ chars): JEAN, JOSE, CAIO, LUAN, etc |
| v1.28.10 | Fix NER - completar nomes que terminam em preposi√ß√£o (DOS, DE, DA, E): busca palavra seguinte no texto original |
| v1.28.09 | Fix feedback visual ao detectar nomes na anonimiza√ß√£o de provas: `setDetectingNames(true)` imediato antes de extrair PDF |
| v1.28.08 | Overlay "IA Local Processando" (componente `LocalAIProcessingOverlay`): feedback visual durante gera√ß√£o de embedding no editor individual e GlobalEditorModal |
| v1.28.07 | Badge IA Local no GlobalEditorModal (header do painel de sugest√µes) |
| v1.28.06 | Badge IA Local em todos editores (individual, fullscreen, global); Fix UI freeze ao ativar split view (yield antes de onFindSuggestions) |
| v1.28.05 | Fix badge IA Local: cache agora salva { suggestions, source } em vez de apenas array |
| v1.28.04 | Badge "ü§ñ IA Local" nas sugest√µes quando v√™m de embeddings; findSuggestions retorna { suggestions, source } |
| v1.28.03 | Fix UI freeze ao abrir editor: yield (setTimeout) antes de getEmbedding para UI atualizar primeiro |
| v1.28.02 | Sugest√µes de modelos via IA Local: toggle em Config IA > Modelos para usar embeddings ao inv√©s de Claude API; ~100ms lat√™ncia vs 2-5s; zero custo; funciona offline |
| v1.28.01 | Bot√£o X e ESC para limpar campos de busca (5 campos); Toggle sem√¢ntico (üß†) como padr√£o ao habilitar busca sem√¢ntica em Config IA |
| v1.28.00 | Remo√ß√£o da gera√ß√£o inline de embeddings para Legisla√ß√£o e Jurisprud√™ncia (agora apenas via importa√ß√£o JSON do Python); redu√ß√£o de ~220 linhas de c√≥digo; simplifica√ß√£o da UI em Config IA |
| v1.27.02 | Gera√ß√£o autom√°tica de embedding em todos os cen√°rios de modelo (novo, editar, duplicar, quick edit, salvar como novo, importar, bulk); feedback visual "Salvando..." no bot√£o durante gera√ß√£o; fix UI freezing (yield) |
| v1.27.01 | Busca Sem√¢ntica na aba Modelos: toggle üß†/üî§, embeddings inline nos modelos, gera√ß√£o em lote via Configura√ß√µes IA, searchModelsBySimilarity, fix bug `local/local` no path do modelo Search |
| v1.27.00 | Busca Sem√¢ntica na Jurisprud√™ncia: JurisEmbeddingsService, toggle üß†/üî§ na aba, chunking para teses longas (IRR/IAC), threshold separado, script Python `generate_juris_embeddings.py` |
| v1.26.05 | Busca sem√¢ntica mostra artigo completo (caput + ¬ß/incisos/al√≠neas) com destaque amarelo no trecho similar |
| v1.26.04 | Script Python `generate_embeddings.py` para gerar embeddings offline + bot√£o "Importar JSON" no Sentencify |
| v1.26.03 | Fix property name: `allArticles` ‚Üí `artigos` (hook retorna `artigos`, n√£o `allArticles`) |
| v1.26.02 | Fix `legislacao is not defined` + Gera√ß√£o incremental de embeddings (s√≥ processa artigos novos, n√£o regenera existentes) |
| v1.26.01 | Fix logs initPipeline ([NER]‚Üí[SEARCH/NER]) + Persist√™ncia Search (auto-init ao recuperar sess√£o) + Auto-unload ao desativar (libera mem√≥ria) |
| v1.26.00 | Busca Sem√¢ntica na Legisla√ß√£o: Modelo E5-base (multilingual-e5-base) com embeddings por item (caput/¬ß/inciso), toggle üß†/üî§ na aba Legisla√ß√£o, threshold configur√°vel, EmbeddingsService para IndexedDB |
| v1.25.26 | Fix NER: Modal de provas usa texto correto (n√£o peti√ß√£o/contesta√ß√£o) + Fix re-inicializa√ß√£o ap√≥s disable/enable (limpa initPromises) |
| v1.25.25 | Cleanup: Remover logs de debug do NER (manteve apenas Fuzzy merge e resultado final) |
| v1.25.24 | Fix NER: Limpar gent√≠licos do final dos nomes ap√≥s fuzzy dedup ("AURIAN...BRASILEIRA" ‚Üí "AURIAN...SILVA") |
| v1.25.23 | Fix NER: Separar STOP_WORDS em contains/exact - "ALMEIDA" era filtrado por conter "ME" (Microempresa). Usa word boundary para palavras curtas |
| v1.25.22 | Fix NER: Filtrar gent√≠licos (paraense, paulista, brasileiro...) + Debug logs para investigar nomes perdidos no fuzzy dedup |
| v1.25.21 | Auto-unload NER: Modelo descarregado da mem√≥ria ao desligar anonimiza√ß√£o (libera ~200-300MB RAM), arquivos mantidos no IndexedDB para re-init r√°pido |
| v1.25.20 | UI: Se√ß√£o "IA Offline" movida para dentro de Anonimiza√ß√£o (s√≥ aparece quando ativo) + Contraste corrigido nas badges de arquivo no tema claro |
| v1.25.19 | Fix: Limpar nomes de anonimiza√ß√£o ao limpar projeto + Bot√£o "Detectar Nomes" funcional nos modais de prova |
| v1.25.18 | Memory Leak Fix: blur listener com handler nomeado + cleanup, helper extractPlainText (evita DOM parsing) |
| v1.25.17 | Fuzzy Deduplication para varia√ß√µes de nomes (Renald/Ranald/Nald ‚Üí manter mais longo). Similarity >70% = merge |
| v1.25.16 | Segment Title Case (converte segmentos ALL CAPS, n√£o chunk inteiro) + Regex remove siglas de estado (AP, SP, RJ) |
| v1.25.15 | Smart Title Case para ALL CAPS (modelo cased confunde >70% mai√∫sculas) + Regex Resgate padr√£o "NOME, brasileiro" |
| v1.25.14 | Debug NER detalhado + filtro falsos positivos (V.EXA, LTDA, RECLAMANTE, etc.). Teste sanidade com frase completa |
| v1.25.02 | IA Offline NER: AIModelService com script injection e WASM trap, UI upload modelo NER nas Configura√ß√µes IA, bot√£o "Detectar Nomes" no modal anonimiza√ß√£o, fun√ß√£o detectarNomesAutomaticamente |
| v1.25.01 | Dashboard de tokens: Adicionado Gemini 3 Flash ($0.50/1M input, $3.00/1M output) √†s estimativas de custo |
| v1.25.00 | Otimiza√ß√£o de cache: cache_control em contesta√ß√µes, complementares e provas (economia ~40-50% em tokens) |
| v1.24.00 | Sistema de Versionamento do campo fundamenta√ß√£o: `useFieldVersioning` hook, `VersionSelect` dropdown, salva vers√£o ao blur, restaura vers√µes anteriores (salva atual antes), integrado no GlobalEditorModal e DecisionEditorContainer |
| v1.22.03 | Fix: filtro Informativo faltando no modal de jurisprudencia do editor |
| v1.22.02 | Fix: contraste ruim das tags de status no tema claro (jurisprudencia) |
| v1.22.01 | Fix: tokenMetrics nao persistia apos F5 (faltava trigger no auto-save) |
| v1.22.00 | Centralizacao prompts mini-relatorios + parametros LLM otimizados (20 chamadas) |
| v1.21.25 | Parametros LLM especificos para revisao (temperature=0.2, topP=0.9, topK=40) |
| v1.21.24 | Prompt revis√£o completo Opus 4.5 - protocolo 5 fases, 6 exemplos, 10 regras, tabela quantitativa, nota A/B/C/D |
| v1.21.21 | Bot√£o "Revisar Senten√ßa" na aba t√≥picos - an√°lise cr√≠tica por IA (omiss√µes, contradi√ß√µes, obscuridades) |
| v1.21.20 | Filtro "Informativo" na aba de jurisprud√™ncia + Script convert-informativos.js + JSON informativos-tst.json |
| v1.21.19 | Fix: tokenMetrics perdido na importa√ß√£o de projeto (faltava setProofSendFullContent) |
| v1.21.18 | Fix: t√≠tulo FUNDAMENTA√á√ÉO alinhado √† esquerda na exporta√ß√£o de minuta |
| v1.21.6 | Modal nomes no Assistente IA com provas vinculadas + Aviso visual PDF com anonimiza√ß√£o ativa |
| v1.21.5 | Anonimiza√ß√£o completa provas: modal nomes na extra√ß√£o, texto anonimizado ao enviar, bloqueio visual PDF puro |
| v1.21.4 | Fix hover bot√µes fullscreen: hover-slate-500 para contraste em ambos os temas |
| v1.21.3 | Anonimiza√ß√£o de provas na entrada: modal nomes, persist√™ncia, nomesUsuario em analyzeProof |
| v1.21.2 | Fix: respeitar modo de processamento (proofProcessingModes) ao enviar provas √† LLM |
| v1.20.0 | Fix duplica√ß√£o t√≥picos complementares + VirtualList altura din√¢mica (Legisla√ß√£o) |
| v1.19.1 | Fix: onInsertResponse assinatura corrigida + normalizeHTMLSpacing no global |
| v1.19.0 | Chat interativo no assistente IA + INSTRUCAO_NAO_PRESUMIR + preservarAnonimizacao condicional |
| v1.18.4 | Fix copyHandlerRef undefined in QuillFieldEditor cleanup |
| v1.14.0 | Detec√ß√£o TF-IDF de similaridade + Bot√£o "Salvar como Modelo" + Compara√ß√£o lado a lado |
| v1.12.27 | Progresso de extra√ß√£o inline no ProofCard (n√£o mais banner de erro) |

**Last Updated**: 2025-12-29
- sempre atualize a vers√£o nas altera√ß√µes realizadas